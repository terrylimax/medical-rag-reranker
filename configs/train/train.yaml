# Training + Trainer settings
seed: 42
batch_size: 8
num_workers: 2

lr: 2e-5
weight_decay: 0.01

max_epochs: 1
accelerator: auto
devices: 1
gradient_clip_val: 1.0
log_every_n_steps: 10

# Helpful for fast, deterministic grading runs
# (set to 1.0 to use the full dataloader)
limit_train_batches: 200
limit_val_batches: 50
